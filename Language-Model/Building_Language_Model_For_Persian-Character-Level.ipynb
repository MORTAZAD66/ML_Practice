{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building Character Level Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A **language model** assigns a probability to every sequence of words.\n",
    "\n",
    "$$P(w_1, w_2,\\dots, w_n)=P(w_1)P(w_2|w_1)P(w_3|w_1,w_2) \\times \\dots \\times P(w_n|w_1,w_2, \\dots, w_{n-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **Translation**: We can compare different orderings of words:\n",
    "<h6 align=\"center\">P(he likes apple) > P(apple likes he)</h6>\n",
    "<br>\n",
    "- **Speech Recognition**: We can choose words:\n",
    "<h6 align=\"center\">P(he likes apple) > P(apple licks he)</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#from utils import *\n",
    "#from data_utils import Vocabulary\n",
    "#from train_utils import train\n",
    "\n",
    "from IPython.core.debugger import Pdb  ## DEBUGGING ##\n",
    "\n",
    "# setup\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12., 6.)\n",
    "pdb = Pdb()\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def plot_loss(trn_hist, val_hist):\n",
    "    plt.plot(trn_hist, label='Training Loss')\n",
    "    plt.plot(val_hist, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: invalid escape sequence '\\u'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:35: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\u'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:35: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/tmp/ipykernel_1830388/2014688387.py:27: SyntaxWarning: invalid escape sequence '\\u'\n",
      "  text = re.sub(b'\\u200c'.decode(\"utf-8\", \"strict\"), \" \", text)   # replace half-spaces with spaces\n",
      "/tmp/ipykernel_1830388/2014688387.py:31: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  text = re.sub('\\.', ' .', text)\n",
      "/tmp/ipykernel_1830388/2014688387.py:35: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  text = re.sub('\\. \\. \\.', '...', text)\n"
     ]
    }
   ],
   "source": [
    "## Helper Functions\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "NLP = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def to_var(x, volatile=False):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x, volatile=volatile)\n",
    "\n",
    "\n",
    "def detach(x):\n",
    "    \"\"\"Wraps hidden states in new tensors, detaching them from their history.\"\"\"\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach()\n",
    "    else:\n",
    "        return tuple(detach(v) for v in x)\n",
    "\n",
    "    \n",
    "    \n",
    "def tokenizer(text):\n",
    "    text = re.sub(b'\\u200c'.decode(\"utf-8\", \"strict\"), \" \", text)   # replace half-spaces with spaces\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('-', ' - ', text)\n",
    "    text = re.sub('[ ]+', ' ', text)\n",
    "    text = re.sub('\\.', ' .', text)\n",
    "    text = re.sub('\\،', ' ،', text)\n",
    "    text = re.sub('\\؛', ' ؛', text)\n",
    "    text = re.sub('\\؟', ' ؟', text)\n",
    "    text = re.sub('\\. \\. \\.', '...', text)\n",
    "    \n",
    "    return [w.text for w in NLP.tokenizer(str(text))]\n",
    "\n",
    "class Vocabulary(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.word2count = {}\n",
    "        self.num_words = 0\n",
    "        \n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        \n",
    "    def add_words(self, words):\n",
    "        for word in words:\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_words\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def train_epoch(epoch, model, trn_ids, \n",
    "                criterion, optimizer, scheduler, \n",
    "                num_epochs, batch_size, seq_length):\n",
    "    \n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    states = model.init_hidden(batch_size)\n",
    "    num_batches = trn_ids.size(1) // seq_length    \n",
    "    trn_loss = 0.0\n",
    "    trn_acc = 0.0\n",
    "    \n",
    "    for i in range(0, trn_ids.size(1) - seq_length, seq_length):\n",
    "        inputs = to_var(trn_ids[:, i: i + seq_length])\n",
    "        targets = to_var(trn_ids[:, (i + 1): (i + 1) + seq_length].contiguous())\n",
    "                \n",
    "        # Forward\n",
    "        states = detach(states)\n",
    "        outputs, states = model(inputs, states)\n",
    "        \n",
    "        # accuracy\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "        acc = torch.mean((predictions == targets.view(-1)).float())\n",
    "        trn_acc = (trn_acc * i + acc.item()) / (i + 1) \n",
    "        \n",
    "        # loss\n",
    "        loss = criterion(outputs, targets.view(-1))\n",
    "        trn_loss = (trn_loss * i + loss.item()) / (i + 1)  \n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.3)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # report\n",
    "        step = (i + 1) // seq_length\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write('\\rTraining: Epoch [%d/%d], Step [%d/%d], Loss: %.3f, Perp: %.2f, Acc: %-15.2f' % \n",
    "              (epoch + 1, num_epochs, step + 1, num_batches, trn_loss, np.exp(trn_loss), trn_acc))\n",
    "    \n",
    "    return trn_loss\n",
    "\n",
    "\n",
    "def validate_epoch(epoch, model, val_ids, criterion, \n",
    "                   num_epochs, batch_size, seq_length):\n",
    "    \n",
    "    model.eval()\n",
    "    states = model.init_hidden(batch_size)\n",
    "    num_batches = val_ids.size(1) // seq_length        \n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    for i in range(0, val_ids.size(1) - seq_length, seq_length):\n",
    "        inputs = to_var(val_ids[:, i: i + seq_length], volatile=True)\n",
    "        targets = to_var(val_ids[:, (i + 1): (i + 1) + seq_length].contiguous())\n",
    "                \n",
    "        # Forward\n",
    "        states = detach(states)\n",
    "        outputs, states = model(inputs, states)\n",
    "        \n",
    "        # accuracy\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "        acc = torch.mean((predictions == targets.view(-1)).float())\n",
    "        val_acc = (val_acc * i + acc.item()) / (i + 1) \n",
    "        \n",
    "        # loss\n",
    "        loss = criterion(outputs, targets.view(-1))\n",
    "        val_loss = (val_loss * i + loss.item()) / (i + 1)  \n",
    "                \n",
    "        # report\n",
    "        step = (i + 1) // seq_length\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write('\\rValidation: Epoch [%d/%d], Step [%d/%d], Loss: %.3f, Perp: %.2f, Acc: %-15.2f' % \n",
    "              (epoch + 1, num_epochs, step + 1, num_batches, val_loss, np.exp(val_loss), val_acc))\n",
    "        \n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def train(model, trn_ids, val_ids, \n",
    "          criterion, optimizer, scheduler, \n",
    "          num_epochs, batch_size, seq_length):\n",
    "    \n",
    "    best_loss = float('Inf')\n",
    "    best_wgts = None\n",
    "    \n",
    "    trn_hist, val_hist = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        trn_loss = train_epoch(epoch, model, trn_ids, \n",
    "                               criterion, optimizer, scheduler, \n",
    "                               num_epochs, batch_size,  seq_length)\n",
    "        \n",
    "        val_loss = validate_epoch(epoch, model, val_ids, criterion, \n",
    "                                  num_epochs, batch_size, seq_length)\n",
    "        \n",
    "        trn_hist.append(trn_loss)\n",
    "        val_hist.append(val_loss)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_wgts = model.state_dict().copy()\n",
    "            model.save(epoch, val_loss)\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_wgts)\n",
    "    return trn_hist, val_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data_dir = '/mnt/home/mnikzad/ML_Practice/Language-Model/data'\n",
    "train_data = f'{data_dir}/fa.ghomshei.txt'\n",
    "\n",
    "output_dir = f'{data_dir}/char/models'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def cal_stats(corpus_path):\n",
    "    # collect the number of tokens used in each sentence of the corpus in a list\n",
    "    lengths = [len(s) for s in open(corpus_path, encoding='utf8').read().split('\\n')]\n",
    "    \n",
    "    # compute stats\n",
    "    total = sum(lengths)\n",
    "    mean = np.mean(lengths)\n",
    "    std = np.std(lengths)\n",
    "    \n",
    "    # print stats\n",
    "    print('Total characters in the corpus = {}\\n'.format(total))\n",
    "    print('Mean = {:.2f}'.format(mean))\n",
    "    print('Std  = {:.2f}'.format(std))\n",
    "    print('95% confidence interval = [{:.2f}, {:.2f}]'.format(mean-2*std, mean+2*std))\n",
    "    \n",
    "    # plot histogram\n",
    "    plt.hist(lengths, bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in the corpus = 870258\n",
      "\n",
      "Mean = 139.24\n",
      "Std  = 98.89\n",
      "95% confidence interval = [-58.54, 337.02]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cal_stats(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    \n",
    "    def __init__(self, corpus_path):\n",
    "        self.vocabulary = Vocabulary()\n",
    "        self.corpus_path = corpus_path\n",
    "        self.num_sentences = len([line for line in open(corpus_path, encoding='utf8')])\n",
    "    \n",
    "    def get_data(self, batch_size=20, split_ratio=0.2):\n",
    "        \n",
    "        # First pass: add words to the vocabulary\n",
    "        trn_tokens, val_tokens = [], []\n",
    "        with open(self.corpus_path, encoding='utf8') as f:\n",
    "            for line in tqdm_notebook(f, desc='Building Vocab...', total=self.num_sentences):\n",
    "                tokens = line\n",
    "                if len(line) <= 10: continue\n",
    "                if random.random() < split_ratio:\n",
    "                    val_tokens += tokens\n",
    "                else:\n",
    "                    trn_tokens += tokens\n",
    "        \n",
    "        counter = Counter(trn_tokens + val_tokens)        \n",
    "        vocabs = [(w, c) for (w, c) in counter.items()]\n",
    "        \n",
    "        for i, (word, count) in enumerate(sorted(vocabs, key=lambda x: x[1], reverse=True)):\n",
    "            self.vocabulary.word2index[word] = i\n",
    "            self.vocabulary.word2count[word] = count\n",
    "            self.vocabulary.index2word[i] = word\n",
    "            self.vocabulary.num_words += 1        \n",
    "        \n",
    "        # Second pass: Tokenize file content        \n",
    "        # train ids\n",
    "        trn_ids = torch.LongTensor(len(trn_tokens))\n",
    "        for idx, token in enumerate(trn_tokens):\n",
    "            trn_ids[idx] = self.vocabulary.word2index[token] \n",
    "        \n",
    "        # validation ids\n",
    "        val_ids = torch.LongTensor(len(val_tokens))\n",
    "        for idx, token in enumerate(val_tokens):\n",
    "            val_ids[idx] = self.vocabulary.word2index[token] \n",
    "        \n",
    "        num_batches = trn_ids.size(0) // batch_size\n",
    "        trn_ids = trn_ids[: num_batches * batch_size]\n",
    "        \n",
    "        num_batches = val_ids.size(0) // batch_size\n",
    "        val_ids = trn_ids[: num_batches * batch_size]\n",
    "\n",
    "        return trn_ids.view(batch_size, -1), val_ids.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# LSTM hyper-parameters\n",
    "embed_size = 1500\n",
    "hidden_size = 1500\n",
    "num_layers = 2\n",
    "\n",
    "# Training hyper-parameters\n",
    "num_epochs = 40\n",
    "batch_size = 50\n",
    "seq_length = 150\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1830388/4087979219.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(f, desc='Building Vocab...', total=self.num_sentences):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3635267ca4045d2ad4cc69af4efe2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Vocab...:   0%|          | 0/6249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus = Corpus(train_data)\n",
    "trn_ids, val_ids = corpus.get_data(batch_size)\n",
    "vocab_size = len(corpus.vocabulary)\n",
    "\n",
    "# save vocabs and ids\n",
    "pickle.dump(corpus.vocabulary, open(f'{output_dir}/vocab.pkl', 'wb'))\n",
    "np.save(f'{output_dir}/trn_ids.npy', trn_ids.view(-1).numpy())\n",
    "np.save(f'{output_dir}/val_ids.npy', val_ids.view(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "torch.Size([50, 14109])\n",
      "torch.Size([50, 3419])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(corpus.vocabulary)\n",
    "print(vocab_size)\n",
    "print(trn_ids.size())\n",
    "print(val_ids.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  183459\n",
      "ا 94377\n",
      "ن 53363\n",
      "ر 52954\n",
      "ی 51199\n",
      "د 50744\n",
      "و 43438\n",
      "ه 42701\n",
      "م 36849\n",
      "ب 30154\n",
      "ت 27292\n",
      "ک 22516\n",
      "س 17949\n",
      "ش 14869\n",
      "ز 14546\n",
      "خ 13575\n",
      "ل 12004\n",
      "آ 11975\n",
      "گ 10941\n",
      "ف 8676\n"
     ]
    }
   ],
   "source": [
    "most_commons = [(w, c) for (w, c) in corpus.vocabulary.word2count.items()][:20]\n",
    "\n",
    "for w, c in most_commons:\n",
    "    print(w, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM For Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class LSTM_LM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1, drop=0.35, tie=True):\n",
    "        super(LSTM_LM, self).__init__()\n",
    "        \n",
    "        if tie:\n",
    "            embed_size = hidden_size\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "            \n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=0.35)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        if tie:\n",
    "            # Use the same weights both for embedding and classification\n",
    "            self.fc.weight.data = self.embedding.weight.data\n",
    "            \n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (to_var(torch.zeros(self.num_layers, batch_size, self.hidden_size)),\n",
    "                to_var(torch.zeros(self.num_layers, batch_size, self.hidden_size)))\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # embed word ids to vectors\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)  # DROPOUT\n",
    "        \n",
    "        # forward RNN step\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        x = self.dropout(x)  # DROPOUT\n",
    "        \n",
    "        # reshape output to (bs * seq_length, hidden_size)\n",
    "        x = x.contiguous().view(x.size(0) * x.size(1), x.size(2))\n",
    "        \n",
    "        # decode hidden states of all time steps\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x, hidden\n",
    "    \n",
    "    def save(self, epoch, loss, save_to=output_dir):\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "        filename = output_dir + '/lm-quran-char-epoch-{}-em-{}-hi-{}-nl-{}-{:.2f}-{:.2f}.pth'.format(\n",
    "            epoch, self.embed_size, self.hidden_size, self.num_layers, loss, np.exp(loss))\n",
    "        torch.save(self.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tie Weights (Embedding and classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Idea:</h6> Reuse Embeddings for Classification, which greatly reduces the number of trainable parameters:\n",
    "- [Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling (Inan et al. 2016)](https://arxiv.org/pdf/1611.01462.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# model\n",
    "model = LSTM_LM(vocab_size, embed_size, hidden_size, num_layers, drop=0.65)\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if use_gpu:\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1830388/794121866.py:32: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch [1/10], Step [94/94], Loss: 0.441, Perp: 1.56, Acc: 0.86           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1830388/2014688387.py:14: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(x, volatile=volatile)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch [10/10], Step [22/22], Loss: 0.342, Perp: 1.41, Acc: 0.93           "
     ]
    }
   ],
   "source": [
    "hist = train(model, trn_ids, val_ids, \n",
    "             criterion, optimizer, scheduler, \n",
    "             10, batch_size, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_loss(\u001b[38;5;241m*\u001b[39m\u001b[43mhist\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss(*hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'masnavi-lm-char-10-1500-2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Algorithm:</h6>\n",
    "1. **Initialize** the LSTM state (`h`, `c`) with zeros.\n",
    "\n",
    "2. Pick a **random word** from vocabulary as the seed.\n",
    "\n",
    "3. while number of generated samples is less than the desired:\n",
    " \n",
    " 3.1 **Feed** the LSTM using the word generated from previous time-step.\n",
    " \n",
    " 3.2 Perform **forward computations** to create the probabilty distribution vector for vocabularies.\n",
    " \n",
    " 3.3 Pick a **random word** from vocabulary according to the probabilty distribution from LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_sample(model, sample_len):\n",
    "    model.eval()\n",
    "    sample = ''\n",
    "    state = model.init_hidden(1)\n",
    "\n",
    "    # select a random word id to start sampling\n",
    "    probs = torch.ones(vocab_size)\n",
    "    inp = to_var(torch.multinomial(probs, num_samples=1).unsqueeze(1), volatile=True)\n",
    "\n",
    "    for i in tqdm_notebook(range(sample_len)):\n",
    "        output, state = model(inp, state)\n",
    "\n",
    "        # Sample an id\n",
    "#         pdb.set_trace()\n",
    "        probs = output.squeeze().data.exp().cpu()\n",
    "        char_id = torch.multinomial(probs, 1)[0]\n",
    "\n",
    "        # Feed sampled word id to next time step\n",
    "        inp.data.fill_(char_id)\n",
    "\n",
    "        # write to file\n",
    "        char_id_sample = char_id.item()\n",
    "        sample += corpus.vocabulary.index2word[char_id_sample]\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1830388/2014688387.py:14: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(x, volatile=volatile)\n",
      "/tmp/ipykernel_1830388/200812823.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(sample_len)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df1afe61cd24fe894b65a59e4c8a3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به روی آنها آیند گروهی هم از آشان می‌ترسم.\n",
      "پس همه فرشتگان غذا جهنم را از (دین) خود برگردانیدیم (و به او ایمان آورد) بر شما گواهی می‌دهیم که تو را به رسالت فرستادیم، صالح به قوم خود گفت: به خدا کافر شو؛ پس از آنکه خدا مقام ایمان را آفریده برای شما بیان کردیم، آنان را از او در گذشت که اوست بسیار آمرزنده و مهربانم.\n",
      "و نیز عنوانش به کافران گویند: این وعده قیامت کی خواهد بود اگر می‌خواستیم، همه از تو فرستادیم، آیا بعضی دیگر در زمین بداند مالک و گواه مردم سخت ظرم و سعادت مردم است.\n",
      "و فرعون به سراب آنها (به مکانی) بدین روشنی بیان می‌کند.\n",
      "و آنان که به آیات خدا و شهود لقای او کافر شدند آنها از رحمت (و نعمت بهشت) من ناامیدند و سخت به عذاب دردناک گرفتار خواهند شد.\n",
      "و کافران گفتند: چرا این قرآن برای ما بیاوری که ما را از تعبیر آن آگاه کن، که تو را از دیارشان بیرون کرد و هرگز نقض عیسی نیست، پیش از اینها طفل یکبیده (و ناگاه) به سر نگیری و (در نظر دین) ما فرشتگان را فرستادیم، گفت: ای قوم، این خلاف را چنین احسان بسیار داده‌ایم و با آنان هرگی هستیم تا از جنس بزرگ خود (می‌توانید) صید کنید. و چون ایمان آوردند ما عذاب ذلت را در دنیا از مال خود نفقی دارند به آنان برگرداند و به آنها علم کتاب (احکام شریعت) و حقایق حکمت می‌شماست، و از او در بهشت آن بیشتر مرد و زن مردم (هدایت پذیرفتند و) سخت هراسان بی شیرین سبز گیرد و راه (سعادت) ننماید.\n",
      "و مثل آنان که مالشان را در راه خدا انفاق کنید درباره پیری وادی می‌شود.\n",
      "و یکی از آیات (قدرت) او آنکه آسمان را برافراشت و فرو بارید از آسمان آبی که به سبب آن بیرون آورد میوه‌های گوناگون برای روزی شما، پس کسی را مثل و مانند او قرار ندهید در حالی که مردان و زنان مؤمن حسن ظنّشان درباره یکدیگر بیشتر شده و گویند: این وعده قیامت اگر قابل نیستند که با من جدل و اطاعت می‌کردید و از پی شما آب دریا راه می‌یابید؟ (آن خدایی را تسبیح و ستایش گویید که) زنده را از مرده و مرده را از زنده برانگیزی و به هم در قیامت نمی‌گروند.\n",
      "و شما فریب و دسوی بسیار بد مانه و خوش‌های من صلاح دانیم و هر به ثواب خدا نزدیک نشوید، که زیانکاران عالمند.\n",
      "ای رسول، جز این نبود که گفتار شما را شبانگاه است شش و ریب می‌شوند.\n",
      "چون فرشتگان بر ما نگهبان او (یعنی فرشتگانی که صالح را پنهان می‌داشت در حضور میوه‌ها ب\n"
     ]
    }
   ],
   "source": [
    "sample = get_sample(model, 2000)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('sample.txt', 'w', encoding='utf8') as f:\n",
    "    f.write(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load a pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = LSTM_LM(vocab_size, embed_size=1500, hidden_size=1500, num_layers=2)\n",
    "model.load_state_dict(torch.load('masnavi-lm-char-10-1500-2.pth'))\n",
    "if use_gpu:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = get_sample(model, 2000)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Droput is ineffective for recurrent layers (evantually all hidden units goes to zero)\n",
    "- Easy solution: use dropout only at the input and output of recurrent layers.\n",
    "- Also, it is possible and common to use dropout between recurrent layers at different depths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "def forward(self, inp, hidden):\n",
    "    # embed word ids to vectors\n",
    "    x = self.embedding(inp)\n",
    "    x = self.dropout(x)  ### DROPOUT ###\n",
    "        \n",
    "    # forward RNN step\n",
    "    x, hidden = self.lstm(x, hidden)\n",
    "    x = self.dropout(x)  ### DROPOUT ###\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Other Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Sub-word level language models\n",
    "- Character level language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "## Furthere Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "- [Oxford Deep NLP 2017 course](https://github.com/oxford-cs-deepnlp-2017/lectures)\n",
    "- [Natural Language Processing with Deep Learning - Stanford](https://youtu.be/OQQ-W_63UgQ)\n",
    "- [Deep Learning Book - Chapter 10](http://www.deeplearningbook.org/contents/rnn.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
